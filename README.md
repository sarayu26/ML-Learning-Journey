# Machine Learning Learning Journey

Welcome to my Machine Learning Learning Journey repository! This collection showcases a variety of Jupyter/Colab notebooks that document my hands-on experience with fundamental machine learning concepts across classification, regression, and data preprocessing techniques.

---

## Repository Structure

ML-Learning-Journey/
│
├── binary_classification/
│ └── Binary_Classification_Breast_Cancer.ipynb
│
├── multiclass_classification/
│ └── Multiclass_Classification_IRIS_data.ipynb
│
├── regression/
│ ├── simple_Linear_reg.ipynb
│ ├── Call_Housing_model_eval.ipynb
│ └── california_housing.ipynb
│
├── decision_trees/
│ └── Decision_Tress_Iris_Data.ipynb
│
└── README.md


---

## Notebooks Overview

### Binary Classification
- **Binary_Classification_Breast_Cancer.ipynb**  
  Logistic Regression classification on the Breast Cancer Wisconsin dataset, with data preprocessing, feature scaling, model training, and evaluation.

### Multiclass Classification
- **Multiclass_Classification_IRIS_data.ipynb**  
  Logistic Regression applied to the Iris dataset for multiclass classification, including train-test splitting, scaling, performance metrics, and confusion matrix.

### Regression
- **simple_Linear_reg.ipynb**  
  Simple linear regression predicting exam scores based on hours studied with synthetic data generation, visualization, model training, and evaluation.
- **Call_Housing_model_eval.ipynb**  
  Linear Regression applied on the California Housing dataset with detailed model evaluation metrics.
- **california_housing.ipynb**  
  Exploratory data analysis and feature engineering on the California Housing dataset to prepare for regression tasks.

### Decision Trees
- **Decision_Tress_Iris_Data.ipynb**  
  Decision Tree classifier on the Iris dataset, including data preprocessing, model building, and result visualization.

---

## How to Use

1. Clone the repository to your local machine or open individual notebooks in [Google Colab](https://colab.research.google.com/).
2. Install any necessary dependencies using `pip install` if running locally.
3. Run the notebook cells step-by-step to explore data loading, preprocessing, modeling, and evaluation.

---

## Future Goals

- Expand with additional machine learning algorithms like SVM, Random Forests, and Gradient Boosting.
- Incorporate deep learning models using TensorFlow/Keras or PyTorch.
- Perform hyperparameter tuning and cross-validation examples.
- Add deployment projects including Flask/Django APIs and cloud services.

---

## Contact

Feel free to reach out via GitHub or LinkedIn for collaboration, questions, or feedback.

---
*Thank you for exploring my machine learning projects!*


